{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Đọc file csv và gắng index với giá Close\n",
    "# data = pd.read_csv('/content/drive/MyDrive/Dataset BA/DXG Price History_32019-32024.csv')\n",
    "\n",
    "dxg_dataset = pd.read_csv('/content/drive/MyDrive/Dataset BA/DXG.csv')\n",
    "qcg_dataset =  pd.read_csv('/content/drive/MyDrive/Dataset BA/QCG.csv')\n",
    "vhm_dataset = pd.read_csv('/content/drive/MyDrive/Dataset BA/VHM.csv')\n",
    "\n",
    "# Tiền xử lí dữ liệu\n",
    "# Hàm chuyển đổi \"Volume\" từ chuỗi sang số\n",
    "def convert_volume_to_number(volume_str):\n",
    "    if volume_str[-1] == 'K':\n",
    "        return int(float(volume_str[:-1]) * 1000)\n",
    "    elif volume_str[-1] == 'M':\n",
    "        return int(float(volume_str[:-1]) * 1000000)\n",
    "    elif volume_str[-1] == 'B':\n",
    "        return int(float(volume_str[:-1]) * 1000000000)\n",
    "    else:\n",
    "        return int(volume_str)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho cột \"Volume\"\n",
    "# data[\"Volume\"] = data[\"Volume\"].apply(convert_volume_to_number)\n",
    "\n",
    "dxg_dataset[\"Volume\"] = dxg_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "qcg_dataset[\"Volume\"] = qcg_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "vhm_dataset[\"Volume\"] = vhm_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "\n",
    "\n",
    "\n",
    "# Hàm chuyển đổi \"Change %\" từ chuỗi sang số\n",
    "def convert_change_to_number(change_str):\n",
    "    new_change = float(change_str.strip('%')) / 100\n",
    "    return new_change\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho cột \"Change %\"\n",
    "# data[\"Change %\"] = data[\"Change %\"].apply(convert_change_to_number)\n",
    "vhm_dataset[\"Change %\"] = vhm_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "dxg_dataset[\"Change %\"] = dxg_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "qcg_dataset[\"Change %\"] = qcg_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "\n",
    "# Hàm chuyển giá từ chuỗi sang số\n",
    "def convert_str_to_number(str):\n",
    "    return float(str.replace(',', ''))\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của DXG\n",
    "dxg_dataset['Close'] = dxg_dataset['Close'].apply(convert_str_to_number)\n",
    "dxg_dataset['Open'] = dxg_dataset['Open'].apply(convert_str_to_number)\n",
    "dxg_dataset['High'] = dxg_dataset['High'].apply(convert_str_to_number)\n",
    "dxg_dataset['Low'] = dxg_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của VHM\n",
    "vhm_dataset['Close'] = vhm_dataset['Close'].apply(convert_str_to_number)\n",
    "vhm_dataset['Open'] = vhm_dataset['Open'].apply(convert_str_to_number)\n",
    "vhm_dataset['High'] = vhm_dataset['High'].apply(convert_str_to_number)\n",
    "vhm_dataset['Low'] = vhm_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của QCG\n",
    "qcg_dataset['Close'] = qcg_dataset['Close'].apply(convert_str_to_number)\n",
    "qcg_dataset['Open'] = qcg_dataset['Open'].apply(convert_str_to_number)\n",
    "qcg_dataset['High'] = qcg_dataset['High'].apply(convert_str_to_number)\n",
    "qcg_dataset['Low'] = qcg_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# df1=data.reset_index()['Close']\n",
    "\n",
    "vhm_dataset\n",
    "dxg_dataset\n",
    "qcg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index cho cột close\n",
    "df1=dxg_dataset.reset_index()['Close']\n",
    "df2=vhm_dataset.reset_index()['Close']\n",
    "df3=qcg_dataset.reset_index()['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scaler data\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "df2=scaler.fit_transform(np.array(df2).reshape(-1,1))\n",
    "df3=scaler.fit_transform(np.array(df3).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Chia train test cho DXG\n",
    "dxg_train_size = int(0.7 * len(df1))\n",
    "dxg_test_size = int(0.2 * len(df1))\n",
    "dxg_val_size = len(df1) - dxg_train_size - dxg_test_size\n",
    "\n",
    "dxg_train_data = df1[:dxg_train_size]\n",
    "dxg_test_data = df1[dxg_train_size:dxg_train_size+dxg_test_size]\n",
    "dxg_val_data = df1[dxg_train_size+dxg_test_size:]\n",
    "\n",
    "# 4. Chia train test cho VHM\n",
    "vhm_train_size = int(0.7 * len(df2))\n",
    "vhm_test_size = int(0.2 * len(df2))\n",
    "vhm_val_size = len(df2) - vhm_train_size - vhm_test_size\n",
    "\n",
    "vhm_train_data = df2[:vhm_train_size]\n",
    "vhm_test_data = df2[vhm_train_size:vhm_train_size+vhm_test_size]\n",
    "vhm_val_data = df2[vhm_train_size+vhm_test_size:]\n",
    "\n",
    "# 4. Chia train test cho QCG\n",
    "qcg_train_size = int(0.7 * len(df3))\n",
    "qcg_test_size = int(0.2 * len(df3))\n",
    "qcg_val_size = len(df3) - qcg_train_size - qcg_test_size\n",
    "\n",
    "qcg_train_data = df3[:qcg_train_size]\n",
    "qcg_test_data = df3[qcg_train_size:qcg_train_size+qcg_test_size]\n",
    "qcg_val_data = df3[qcg_train_size+qcg_test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Hàm Create Dataset\n",
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, X=0,1,2,3-----99   Y=100\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Reshape into X=t,t+1,t+2..t+99 and Y=t+100\n",
    "\n",
    "time_step = 30\n",
    "#Create data X, Y for DXG\n",
    "dxg_X_train, dxg_y_train = create_dataset(dxg_train_data, time_step)\n",
    "dxg_X_val, dxg_yval = create_dataset(dxg_val_data, time_step)\n",
    "dxg_X_test, dxg_ytest = create_dataset(dxg_test_data, time_step)\n",
    "\n",
    "#Create data X, Y for VHM\n",
    "vhm_X_train, vhm_y_train = create_dataset(vhm_train_data, time_step)\n",
    "vhm_X_val, vhm_yval = create_dataset(vhm_val_data, time_step)\n",
    "vhm_X_test, vhm_ytest = create_dataset(vhm_test_data, time_step)\n",
    "\n",
    "#Create data X, Y for DXG\n",
    "qcg_X_train, qcg_y_train = create_dataset(qcg_train_data, time_step)\n",
    "qcg_X_val, qcg_yval = create_dataset(qcg_val_data, time_step)\n",
    "qcg_X_test, qcg_ytest = create_dataset(qcg_test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reshape input of DXG to be [samples, time steps, features] which is required for TimesNet\n",
    "dxg_X_train =dxg_X_train.reshape(dxg_X_train.shape[0],dxg_X_train.shape[1] , 1)\n",
    "dxg_X_test = dxg_X_test.reshape(dxg_X_test.shape[0],dxg_X_test.shape[1] , 1)\n",
    "dxg_X_val = dxg_X_val.reshape(dxg_X_val.shape[0],dxg_X_val.shape[1] , 1)\n",
    "\n",
    "# 7. Reshape input of VHM to be [samples, time steps, features] which is required for TimesNet\n",
    "vhm_X_train =vhm_X_train.reshape(vhm_X_train.shape[0],vhm_X_train.shape[1] , 1)\n",
    "vhm_X_test = vhm_X_test.reshape(vhm_X_test.shape[0],vhm_X_test.shape[1] , 1)\n",
    "vhm_X_val = vhm_X_val.reshape(vhm_X_val.shape[0],vhm_X_val.shape[1] , 1)\n",
    "\n",
    "# 7. Reshape input of QCG to be [samples, time steps, features] which is required for TimesNet\n",
    "qcg_X_train =qcg_X_train.reshape(qcg_X_train.shape[0],qcg_X_train.shape[1] , 1)\n",
    "qcg_X_test = qcg_X_test.reshape(qcg_X_test.shape[0],qcg_X_test.shape[1] , 1)\n",
    "qcg_X_val = qcg_X_val.reshape(qcg_X_val.shape[0],qcg_X_val.shape[1] , 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Define TimesNet Model\n",
    "\n",
    "def build_tcn_model(timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "n_features = 1  # Since we have only one feature (the price)\n",
    "dxg_model = build_tcn_model(time_step, n_features)\n",
    "vhm_model = build_tcn_model(time_step, n_features)\n",
    "qcg_model = build_tcn_model(time_step, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model \n",
    "dxg_model.fit(dxg_X_train,dxg_y_train,validation_data=(dxg_X_test,dxg_ytest),epochs=100,batch_size=64,verbose=1)\n",
    "vhm_model.fit(vhm_X_train,vhm_y_train,validation_data=(vhm_X_test,vhm_ytest),epochs=100,batch_size=64,verbose=1)\n",
    "qcg_model.fit(qcg_X_train,qcg_y_train,validation_data=(qcg_X_test,qcg_ytest),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Dự báo dữ liệu test, val cho DXG\n",
    "print(\"DXG Pred\")\n",
    "dxg_y_pred=dxg_model.predict(dxg_X_test)\n",
    "dxg_y_pred_val=dxg_model.predict(dxg_X_val)\n",
    "\n",
    "dxg_y_pred_new = scaler.inverse_transform(dxg_y_pred.reshape(1, -1))\n",
    "dxg_y_test_new = scaler.inverse_transform(np.array([dxg_ytest], dtype=np.float32))\n",
    "\n",
    "# 10. Dự báo dữ liệu test, val cho VHM\n",
    "print(\"VHM Pred\")\n",
    "vhm_y_pred=vhm_model.predict(vhm_X_test)\n",
    "vhm_y_pred_val=vhm_model.predict(vhm_X_val)\n",
    "\n",
    "vhm_y_pred_new = scaler.inverse_transform(vhm_y_pred.reshape(1, -1))\n",
    "vhm_y_test_new = scaler.inverse_transform(np.array([vhm_ytest], dtype=np.float32))\n",
    "\n",
    "# 10. Dự báo dữ liệu test, val cho QCG\n",
    "print(\"QCG Pred\")\n",
    "qcg_y_pred=qcg_model.predict(qcg_X_test)\n",
    "qcg_y_pred_val=qcg_model.predict(qcg_X_val)\n",
    "\n",
    "qcg_y_pred_new = scaler.inverse_transform(qcg_y_pred.reshape(1, -1))\n",
    "qcg_y_test_new = scaler.inverse_transform(np.array([qcg_ytest], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "# Hàm tính MDA\n",
    "def calculate_mda(y_true, y_pred):\n",
    "    y_true_diff = np.diff(y_true)\n",
    "    y_pred_diff = np.diff(y_pred)\n",
    "    correct_direction = np.sign(y_true_diff) == np.sign(y_pred_diff)\n",
    "    return np.mean(correct_direction) * 100\n",
    "\n",
    "# Tính toán RMSE, MAE và MAPE trên tập test của DXG\n",
    "dxg_test_score_rmse = np.sqrt(mean_squared_error(dxg_y_test_new, dxg_y_pred_new))\n",
    "dxg_test_score_mape = mean_absolute_percentage_error(dxg_y_test_new, dxg_y_pred_new) * 100\n",
    "dxg_test_score_mda = calculate_mda(dxg_y_test_new, dxg_y_pred_new)\n",
    "\n",
    "print('RMSE trên tập test của DXG là:', dxg_test_score_rmse)\n",
    "print('MAPE trên tập test của DXG là:', dxg_test_score_mape, '%')\n",
    "print('MDA trên tập test của DXG là:', dxg_test_score_mda, '%')\n",
    "\n",
    "# Tính toán RMSE, MAE và MAPE trên tập test của VHM\n",
    "vhm_test_score_rmse = np.sqrt(mean_squared_error(vhm_y_test_new, vhm_y_pred_new))\n",
    "vhm_test_score_mape = mean_absolute_percentage_error(vhm_y_test_new, vhm_y_pred_new) * 100\n",
    "vhm_test_score_mda = calculate_mda(vhm_y_test_new, vhm_y_pred_new)\n",
    "\n",
    "print('RMSE trên tập test của VHM là:', vhm_test_score_rmse)\n",
    "print('MAPE trên tập test của VHM là:', vhm_test_score_mape, '%')\n",
    "print('MDA trên tập test của VHM là:', vhm_test_score_mda, '%')\n",
    "\n",
    "# Tính toán RMSE, MAE và MAPE trên tập test của QCG\n",
    "qcg_test_score_rmse = np.sqrt(mean_squared_error(qcg_y_test_new, qcg_y_pred_new))\n",
    "qcg_test_score_mape = mean_absolute_percentage_error(qcg_y_test_new, qcg_y_pred_new) * 100\n",
    "qcg_test_score_mda = calculate_mda(qcg_y_test_new, qcg_y_pred_new)\n",
    "\n",
    "print('RMSE trên tập test của QCG là:', qcg_test_score_rmse)\n",
    "print('MAPE trên tập test của QCG là:', qcg_test_score_mape, '%')\n",
    "print('MDA trên tập test của QCG là:', qcg_test_score_mda, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Dự báo 30 ngày tiếp theo cho tập DXG \n",
    "dxg_x_input = dxg_val_data[-time_step:].reshape(1, -1, 1)  # Lấy dữ liệu cuối cùng trong tập validation, reshape để phù hợp với input của mô hình\n",
    "dxg_temp_input = list(dxg_x_input.flatten())[:time_step]  # Chuyển dữ liệu thành danh sách và chỉ sử dụng số lượng phần tử bằng số time step\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "dxg_lst_output = []\n",
    "dxg_n_steps = time_step\n",
    "\n",
    "# Dự đoán giá cho 30 ngày tiếp theo\n",
    "for i in range(30):\n",
    "    dxg_x_input = array(dxg_temp_input)  # Sử dụng số lượng phần tử bằng số time step\n",
    "    print(\"{} day input {}\".format(i,dxg_x_input))\n",
    "    dxg_x_input = dxg_x_input.reshape((1, dxg_n_steps, 1))  # Reshape lại để phù hợp với input của mô hình\n",
    "    dxg_yhat = dxg_model.predict(dxg_x_input, verbose=0)  # Dự đoán giá cho ngày tiếp theo\n",
    "    print(\"{} day output {}\".format(i,dxg_yhat))\n",
    "    dxg_temp_input.extend(dxg_yhat[0].tolist())  # Thêm dự đoán vào danh sách\n",
    "    dxg_temp_input = dxg_temp_input[1:]  # Loại bỏ phần tử đầu tiên\n",
    "    dxg_lst_output.extend(dxg_yhat.tolist())  # Thêm dự đoán vào danh sách kết quả\n",
    "\n",
    "print(dxg_lst_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Dự báo 30 ngày tiếp theo cho tập VHM\n",
    "vhm_x_input = vhm_val_data[-time_step:].reshape(1, -1, 1)  # Lấy dữ liệu cuối cùng trong tập validation, reshape để phù hợp với input của mô hình\n",
    "vhm_temp_input = list(vhm_x_input.flatten())[:time_step]  # Chuyển dữ liệu thành danh sách và chỉ sử dụng số lượng phần tử bằng số time step\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "vhm_lst_output = []\n",
    "vhm_n_steps = time_step\n",
    "\n",
    "# Dự đoán giá cho 30 ngày tiếp theo\n",
    "for i in range(30):\n",
    "    vhm_x_input = array(vhm_temp_input)  # Sử dụng số lượng phần tử bằng số time step\n",
    "    print(\"{} day input {}\".format(i,vhm_x_input))\n",
    "    vhm_x_input = vhm_x_input.reshape((1, vhm_n_steps, 1))  # Reshape lại để phù hợp với input của mô hình\n",
    "    vhm_yhat = vhm_model.predict(vhm_x_input, verbose=0)  # Dự đoán giá cho ngày tiếp theo\n",
    "    print(\"{} day output {}\".format(i,vhm_yhat))\n",
    "    vhm_temp_input.extend(vhm_yhat[0].tolist())  # Thêm dự đoán vào danh sách\n",
    "    vhm_temp_input = vhm_temp_input[1:]  # Loại bỏ phần tử đầu tiên\n",
    "    vhm_lst_output.extend(vhm_yhat.tolist())  # Thêm dự đoán vào danh sách kết quả\n",
    "\n",
    "print(vhm_lst_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Dự báo 30 ngày tiếp theo cho tập QCG\n",
    "qcg_x_input = qcg_val_data[-time_step:].reshape(1, -1, 1)  # Lấy dữ liệu cuối cùng trong tập validation, reshape để phù hợp với input của mô hình\n",
    "qcg_temp_input = list(qcg_x_input.flatten())[:time_step]  # Chuyển dữ liệu thành danh sách và chỉ sử dụng số lượng phần tử bằng số time step\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "qcg_lst_output = []\n",
    "qcg_n_steps = time_step\n",
    "\n",
    "# Dự đoán giá cho 30 ngày tiếp theo\n",
    "for i in range(30):\n",
    "    qcg_x_input = array(qcg_temp_input)  # Sử dụng số lượng phần tử bằng số time step\n",
    "    print(\"{} day input {}\".format(i,qcg_x_input))\n",
    "    qcg_x_input = qcg_x_input.reshape((1, qcg_n_steps, 1))  # Reshape lại để phù hợp với input của mô hình\n",
    "    qcg_yhat = qcg_model.predict(qcg_x_input, verbose=0)  # Dự đoán giá cho ngày tiếp theo\n",
    "    print(\"{} day output {}\".format(i,qcg_yhat))\n",
    "    qcg_temp_input.extend(qcg_yhat[0].tolist())  # Thêm dự đoán vào danh sách\n",
    "    qcg_temp_input = qcg_temp_input[1:]  # Loại bỏ phần tử đầu tiên\n",
    "    qcg_lst_output.extend(qcg_yhat.tolist())  # Thêm dự đoán vào danh sách kết quả\n",
    "\n",
    "print(qcg_lst_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.Vẽ hình DXG\n",
    "dxg_train_data_index = pd.RangeIndex(start=0, stop=dxg_train_size, step=1)\n",
    "plt.plot(scaler.inverse_transform(dxg_train_data))\n",
    "dxg_test_data_index = pd.RangeIndex(start=dxg_train_size, stop=dxg_train_size+dxg_test_size, step=1)\n",
    "plt.plot(dxg_test_data_index,scaler.inverse_transform(dxg_test_data))\n",
    "dxg_test_data_index = pd.RangeIndex(start=dxg_train_size+31, stop=dxg_train_size+dxg_test_size, step=1)\n",
    "plt.plot(dxg_test_data_index,scaler.inverse_transform(dxg_y_pred))\n",
    "dxg_val_data_index = pd.RangeIndex(start=dxg_train_size+dxg_test_size, stop=dxg_train_size+dxg_test_size+dxg_val_size, step=1)\n",
    "plt.plot(dxg_val_data_index,scaler.inverse_transform(dxg_val_data))\n",
    "dxg_val_data_index = pd.RangeIndex(start=dxg_train_size+dxg_test_size+31, stop=dxg_train_size+dxg_test_size+dxg_val_size, step=1)\n",
    "plt.plot(dxg_val_data_index,scaler.inverse_transform(dxg_y_pred_val))\n",
    "prediect_data_index = pd.RangeIndex(start=len(df1)-1, stop=len(df1)+29, step=1)\n",
    "plt.plot(prediect_data_index,scaler.inverse_transform(dxg_lst_output))\n",
    "plt.legend(['Train','Test','Predict','Validate','ValidatePred','Predict30days'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.Vẽ hình VHM\n",
    "vhm_train_data_index = pd.RangeIndex(start=0, stop=vhm_train_size, step=1)\n",
    "plt.plot(scaler.inverse_transform(vhm_train_data))\n",
    "vhm_test_data_index = pd.RangeIndex(start=vhm_train_size, stop=vhm_train_size+vhm_test_size, step=1)\n",
    "plt.plot(vhm_test_data_index,scaler.inverse_transform(vhm_test_data))\n",
    "vhm_test_data_index = pd.RangeIndex(start=vhm_train_size+31, stop=vhm_train_size+vhm_test_size, step=1)\n",
    "plt.plot(vhm_test_data_index,scaler.inverse_transform(vhm_y_pred))\n",
    "vhm_val_data_index = pd.RangeIndex(start=vhm_train_size+vhm_test_size, stop=vhm_train_size+vhm_test_size+vhm_val_size, step=1)\n",
    "plt.plot(vhm_val_data_index,scaler.inverse_transform(vhm_val_data))\n",
    "vhm_val_data_index = pd.RangeIndex(start=vhm_train_size+vhm_test_size+31, stop=vhm_train_size+vhm_test_size+vhm_val_size, step=1)\n",
    "plt.plot(vhm_val_data_index,scaler.inverse_transform(vhm_y_pred_val))\n",
    "prediect_data_index = pd.RangeIndex(start=len(df1)-1, stop=len(df1)+29, step=1)\n",
    "plt.plot(prediect_data_index,scaler.inverse_transform(vhm_lst_output))\n",
    "plt.legend(['Train','Test','Predict','Validate','ValidatePred','Predict30days'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.Vẽ hình QCG\n",
    "qcg_train_data_index = pd.RangeIndex(start=0, stop=qcg_train_size, step=1)\n",
    "plt.plot(scaler.inverse_transform(qcg_train_data))\n",
    "qcg_test_data_index = pd.RangeIndex(start=qcg_train_size, stop=qcg_train_size+qcg_test_size, step=1)\n",
    "plt.plot(qcg_test_data_index,scaler.inverse_transform(qcg_test_data))\n",
    "qcg_test_data_index = pd.RangeIndex(start=qcg_train_size+31, stop=qcg_train_size+qcg_test_size, step=1)\n",
    "plt.plot(qcg_test_data_index,scaler.inverse_transform(qcg_y_pred))\n",
    "qcg_val_data_index = pd.RangeIndex(start=qcg_train_size+qcg_test_size, stop=qcg_train_size+qcg_test_size+qcg_val_size, step=1)\n",
    "plt.plot(qcg_val_data_index,scaler.inverse_transform(qcg_val_data))\n",
    "qcg_val_data_index = pd.RangeIndex(start=qcg_train_size+qcg_test_size+31, stop=qcg_train_size+qcg_test_size+qcg_val_size, step=1)\n",
    "plt.plot(qcg_val_data_index,scaler.inverse_transform(qcg_y_pred_val))\n",
    "prediect_data_index = pd.RangeIndex(start=len(df1)-1, stop=len(df1)+29, step=1)\n",
    "plt.plot(prediect_data_index,scaler.inverse_transform(qcg_lst_output))\n",
    "plt.legend(['Train','Test','Predict','Validate','ValidatePred','Predict30days'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
