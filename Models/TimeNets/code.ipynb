{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Đọc file csv và gắng index với giá Close\n",
    "# data = pd.read_csv('/content/drive/MyDrive/Dataset BA/DXG Price History_32019-32024.csv')\n",
    "\n",
    "dxg_dataset = pd.read_csv('/content/drive/MyDrive/Dataset BA/DXG.csv')\n",
    "qcg_dataset =  pd.read_csv('/content/drive/MyDrive/Dataset BA/QCG.csv')\n",
    "vhm_dataset = pd.read_csv('/content/drive/MyDrive/Dataset BA/VHM.csv')\n",
    "\n",
    "# Tiền xử lí dữ liệu\n",
    "# Hàm chuyển đổi \"Volume\" từ chuỗi sang số\n",
    "def convert_volume_to_number(volume_str):\n",
    "    if volume_str[-1] == 'K':\n",
    "        return int(float(volume_str[:-1]) * 1000)\n",
    "    elif volume_str[-1] == 'M':\n",
    "        return int(float(volume_str[:-1]) * 1000000)\n",
    "    elif volume_str[-1] == 'B':\n",
    "        return int(float(volume_str[:-1]) * 1000000000)\n",
    "    else:\n",
    "        return int(volume_str)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho cột \"Volume\"\n",
    "# data[\"Volume\"] = data[\"Volume\"].apply(convert_volume_to_number)\n",
    "\n",
    "dxg_dataset[\"Volume\"] = dxg_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "qcg_dataset[\"Volume\"] = qcg_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "vhm_dataset[\"Volume\"] = vhm_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "\n",
    "\n",
    "\n",
    "# Hàm chuyển đổi \"Change %\" từ chuỗi sang số\n",
    "def convert_change_to_number(change_str):\n",
    "    new_change = float(change_str.strip('%')) / 100\n",
    "    return new_change\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho cột \"Change %\"\n",
    "# data[\"Change %\"] = data[\"Change %\"].apply(convert_change_to_number)\n",
    "vhm_dataset[\"Change %\"] = vhm_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "dxg_dataset[\"Change %\"] = dxg_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "qcg_dataset[\"Change %\"] = qcg_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "\n",
    "# Hàm chuyển giá từ chuỗi sang số\n",
    "def convert_str_to_number(str):\n",
    "    return float(str.replace(',', ''))\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của DXG\n",
    "dxg_dataset['Close'] = dxg_dataset['Close'].apply(convert_str_to_number)\n",
    "dxg_dataset['Open'] = dxg_dataset['Open'].apply(convert_str_to_number)\n",
    "dxg_dataset['High'] = dxg_dataset['High'].apply(convert_str_to_number)\n",
    "dxg_dataset['Low'] = dxg_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của VHM\n",
    "vhm_dataset['Close'] = vhm_dataset['Close'].apply(convert_str_to_number)\n",
    "vhm_dataset['Open'] = vhm_dataset['Open'].apply(convert_str_to_number)\n",
    "vhm_dataset['High'] = vhm_dataset['High'].apply(convert_str_to_number)\n",
    "vhm_dataset['Low'] = vhm_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của QCG\n",
    "qcg_dataset['Close'] = qcg_dataset['Close'].apply(convert_str_to_number)\n",
    "qcg_dataset['Open'] = qcg_dataset['Open'].apply(convert_str_to_number)\n",
    "qcg_dataset['High'] = qcg_dataset['High'].apply(convert_str_to_number)\n",
    "qcg_dataset['Low'] = qcg_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# df1=data.reset_index()['Close']\n",
    "\n",
    "vhm_dataset\n",
    "dxg_dataset\n",
    "qcg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index cho cột close\n",
    "df1=dxg_dataset.reset_index()['Close']\n",
    "df2=vhm_dataset.reset_index()['Close']\n",
    "df3=qcg_dataset.reset_index()['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scaler data\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "df2=scaler.fit_transform(np.array(df2).reshape(-1,1))\n",
    "df3=scaler.fit_transform(np.array(df3).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Chia train test cho DXG\n",
    "dxg_train_size = int(0.7 * len(df1))\n",
    "dxg_test_size = int(0.2 * len(df1))\n",
    "dxg_val_size = len(df1) - dxg_train_size - dxg_test_size\n",
    "\n",
    "dxg_train_data = df1[:dxg_train_size]\n",
    "dxg_test_data = df1[dxg_train_size:dxg_train_size+dxg_test_size]\n",
    "dxg_val_data = df1[dxg_train_size+dxg_test_size:]\n",
    "\n",
    "# 4. Chia train test cho VHM\n",
    "vhm_train_size = int(0.7 * len(df2))\n",
    "vhm_test_size = int(0.2 * len(df2))\n",
    "vhm_val_size = len(df2) - vhm_train_size - vhm_test_size\n",
    "\n",
    "vhm_train_data = df2[:vhm_train_size]\n",
    "vhm_test_data = df2[vhm_train_size:vhm_train_size+vhm_test_size]\n",
    "vhm_val_data = df2[vhm_train_size+vhm_test_size:]\n",
    "\n",
    "# 4. Chia train test cho QCG\n",
    "qcg_train_size = int(0.7 * len(df3))\n",
    "qcg_test_size = int(0.2 * len(df3))\n",
    "qcg_val_size = len(df3) - qcg_train_size - qcg_test_size\n",
    "\n",
    "qcg_train_data = df3[:qcg_train_size]\n",
    "qcg_test_data = df3[qcg_train_size:qcg_train_size+qcg_test_size]\n",
    "qcg_val_data = df3[qcg_train_size+qcg_test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Hàm Create Dataset\n",
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, X=0,1,2,3-----99   Y=100\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Reshape into X=t,t+1,t+2..t+99 and Y=t+100\n",
    "\n",
    "time_step = 30\n",
    "#Create data X, Y for DXG\n",
    "dxg_X_train, dxg_y_train = create_dataset(dxg_train_data, time_step)\n",
    "dxg_X_val, dxg_yval = create_dataset(dxg_val_data, time_step)\n",
    "dxg_X_test, dxg_ytest = create_dataset(dxg_test_data, time_step)\n",
    "\n",
    "#Create data X, Y for VHM\n",
    "vhm_X_train, vhm_y_train = create_dataset(vhm_train_data, time_step)\n",
    "vhm_X_val, vhm_yval = create_dataset(vhm_val_data, time_step)\n",
    "vhm_X_test, vhm_ytest = create_dataset(vhm_test_data, time_step)\n",
    "\n",
    "#Create data X, Y for DXG\n",
    "qcg_X_train, qcg_y_train = create_dataset(qcg_train_data, time_step)\n",
    "qcg_X_val, qcg_yval = create_dataset(qcg_val_data, time_step)\n",
    "qcg_X_test, qcg_ytest = create_dataset(qcg_test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reshape input of DXG to be [samples, time steps, features] which is required for TimesNet\n",
    "dxg_X_train =dxg_X_train.reshape(dxg_X_train.shape[0],dxg_X_train.shape[1] , 1)\n",
    "dxg_X_test = dxg_X_test.reshape(dxg_X_test.shape[0],dxg_X_test.shape[1] , 1)\n",
    "dxg_X_val = dxg_X_val.reshape(dxg_X_val.shape[0],dxg_X_val.shape[1] , 1)\n",
    "\n",
    "# 7. Reshape input of VHM to be [samples, time steps, features] which is required for TimesNet\n",
    "vhm_X_train =vhm_X_train.reshape(vhm_X_train.shape[0],vhm_X_train.shape[1] , 1)\n",
    "vhm_X_test = vhm_X_test.reshape(vhm_X_test.shape[0],vhm_X_test.shape[1] , 1)\n",
    "vhm_X_val = vhm_X_val.reshape(vhm_X_val.shape[0],vhm_X_val.shape[1] , 1)\n",
    "\n",
    "# 7. Reshape input of QCG to be [samples, time steps, features] which is required for TimesNet\n",
    "qcg_X_train =qcg_X_train.reshape(qcg_X_train.shape[0],qcg_X_train.shape[1] , 1)\n",
    "qcg_X_test = qcg_X_test.reshape(qcg_X_test.shape[0],qcg_X_test.shape[1] , 1)\n",
    "qcg_X_val = qcg_X_val.reshape(qcg_X_val.shape[0],qcg_X_val.shape[1] , 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Define TimesNet Model\n",
    "\n",
    "def build_tcn_model(timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(timesteps, n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "n_features = 1  # Since we have only one feature (the price)\n",
    "dxg_model = build_tcn_model(time_step, n_features)\n",
    "vhm_model = build_tcn_model(time_step, n_features)\n",
    "qcg_model = build_tcn_model(time_step, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model \n",
    "dxg_model.fit(dxg_X_train,dxg_y_train,validation_data=(dxg_X_test,dxg_ytest),epochs=100,batch_size=64,verbose=1)\n",
    "vhm_model.fit(vhm_X_train,vhm_y_train,validation_data=(vhm_X_test,vhm_ytest),epochs=100,batch_size=64,verbose=1)\n",
    "qcg_model.fit(qcg_X_train,qcg_y_train,validation_data=(qcg_X_test,qcg_ytest),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Dự báo dữ liệu test, val cho DXG\n",
    "print(\"DXG Pred\")\n",
    "dxg_y_pred=dxg_model.predict(dxg_X_test)\n",
    "dxg_y_pred_val=dxg_model.predict(dxg_X_val)\n",
    "\n",
    "dxg_y_pred_new = scaler.inverse_transform(dxg_y_pred.reshape(1, -1))\n",
    "dxg_y_test_new = scaler.inverse_transform(np.array([dxg_ytest], dtype=np.float32))\n",
    "\n",
    "# 10. Dự báo dữ liệu test, val cho VHM\n",
    "print(\"VHM Pred\")\n",
    "vhm_y_pred=vhm_model.predict(vhm_X_test)\n",
    "vhm_y_pred_val=vhm_model.predict(vhm_X_val)\n",
    "\n",
    "vhm_y_pred_new = scaler.inverse_transform(vhm_y_pred.reshape(1, -1))\n",
    "vhm_y_test_new = scaler.inverse_transform(np.array([vhm_ytest], dtype=np.float32))\n",
    "\n",
    "# 10. Dự báo dữ liệu test, val cho QCG\n",
    "print(\"QCG Pred\")\n",
    "vhm_y_pred=vhm_model.predict(vhm_X_test)\n",
    "vhm_y_pred_val=vhm_model.predict(vhm_X_val)\n",
    "\n",
    "vhm_y_pred_new = scaler.inverse_transform(vhm_y_pred.reshape(1, -1))\n",
    "vhm_y_test_new = scaler.inverse_transform(np.array([vhm_ytest], dtype=np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
