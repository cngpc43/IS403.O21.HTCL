{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Đọc file csv và gắng index với giá Close\n",
    "# data = pd.read_csv('/content/drive/MyDrive/Dataset BA/DXG Price History_32019-32024.csv')\n",
    "\n",
    "dxg_dataset = pd.read_csv('/content/drive/MyDrive/Dataset BA/DXG.csv')\n",
    "qcg_dataset =  pd.read_csv('/content/drive/MyDrive/Dataset BA/QCG.csv')\n",
    "vhm_dataset = pd.read_csv('/content/drive/MyDrive/Dataset BA/VHM.csv')\n",
    "\n",
    "# Tiền xử lí dữ liệu\n",
    "# Hàm chuyển đổi \"Volume\" từ chuỗi sang số\n",
    "def convert_volume_to_number(volume_str):\n",
    "    if volume_str[-1] == 'K':\n",
    "        return int(float(volume_str[:-1]) * 1000)\n",
    "    elif volume_str[-1] == 'M':\n",
    "        return int(float(volume_str[:-1]) * 1000000)\n",
    "    elif volume_str[-1] == 'B':\n",
    "        return int(float(volume_str[:-1]) * 1000000000)\n",
    "    else:\n",
    "        return int(volume_str)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho cột \"Volume\"\n",
    "# data[\"Volume\"] = data[\"Volume\"].apply(convert_volume_to_number)\n",
    "\n",
    "dxg_dataset[\"Volume\"] = dxg_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "qcg_dataset[\"Volume\"] = qcg_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "vhm_dataset[\"Volume\"] = vhm_dataset[\"Volume\"].apply(convert_volume_to_number)\n",
    "\n",
    "\n",
    "\n",
    "# Hàm chuyển đổi \"Change %\" từ chuỗi sang số\n",
    "def convert_change_to_number(change_str):\n",
    "    new_change = float(change_str.strip('%')) / 100\n",
    "    return new_change\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho cột \"Change %\"\n",
    "# data[\"Change %\"] = data[\"Change %\"].apply(convert_change_to_number)\n",
    "vhm_dataset[\"Change %\"] = vhm_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "dxg_dataset[\"Change %\"] = dxg_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "qcg_dataset[\"Change %\"] = qcg_dataset[\"Change %\"].apply(convert_change_to_number)\n",
    "\n",
    "# Hàm chuyển giá từ chuỗi sang số\n",
    "def convert_str_to_number(str):\n",
    "    return float(str.replace(',', ''))\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của DXG\n",
    "dxg_dataset['Close'] = dxg_dataset['Close'].apply(convert_str_to_number)\n",
    "dxg_dataset['Open'] = dxg_dataset['Open'].apply(convert_str_to_number)\n",
    "dxg_dataset['High'] = dxg_dataset['High'].apply(convert_str_to_number)\n",
    "dxg_dataset['Low'] = dxg_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của VHM\n",
    "vhm_dataset['Close'] = vhm_dataset['Close'].apply(convert_str_to_number)\n",
    "vhm_dataset['Open'] = vhm_dataset['Open'].apply(convert_str_to_number)\n",
    "vhm_dataset['High'] = vhm_dataset['High'].apply(convert_str_to_number)\n",
    "vhm_dataset['Low'] = vhm_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho các cột giá trị của QCG\n",
    "qcg_dataset['Close'] = qcg_dataset['Close'].apply(convert_str_to_number)\n",
    "qcg_dataset['Open'] = qcg_dataset['Open'].apply(convert_str_to_number)\n",
    "qcg_dataset['High'] = qcg_dataset['High'].apply(convert_str_to_number)\n",
    "qcg_dataset['Low'] = qcg_dataset['Low'].apply(convert_str_to_number)\n",
    "\n",
    "# df1=data.reset_index()['Close']\n",
    "\n",
    "vhm_dataset\n",
    "dxg_dataset\n",
    "qcg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Index cho cột close\n",
    "df1=dxg_dataset.reset_index()['Close']\n",
    "df2=vhm_dataset.reset_index()['Close']\n",
    "df3=qcg_dataset.reset_index()['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Scaler data\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "df2=scaler.fit_transform(np.array(df2).reshape(-1,1))\n",
    "df3=scaler.fit_transform(np.array(df3).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Chia train test cho DXG\n",
    "dxg_train_size = int(0.7 * len(df1))\n",
    "dxg_test_size = int(0.2 * len(df1))\n",
    "dxg_val_size = len(df1) - dxg_train_size - dxg_test_size\n",
    "\n",
    "dxg_train_data = df1[:dxg_train_size]\n",
    "dxg_test_data = df1[dxg_train_size:dxg_train_size+dxg_test_size]\n",
    "dxg_val_data = df1[dxg_train_size+dxg_test_size:]\n",
    "\n",
    "# 4. Chia train test cho VHM\n",
    "vhm_train_size = int(0.7 * len(df2))\n",
    "vhm_test_size = int(0.2 * len(df2))\n",
    "vhm_val_size = len(df2) - vhm_train_size - vhm_test_size\n",
    "\n",
    "vhm_train_data = df2[:vhm_train_size]\n",
    "vhm_test_data = df2[vhm_train_size:vhm_train_size+vhm_test_size]\n",
    "vhm_val_data = df2[vhm_train_size+vhm_test_size:]\n",
    "\n",
    "# 4. Chia train test cho QCG\n",
    "qcg_train_size = int(0.7 * len(df3))\n",
    "qcg_test_size = int(0.2 * len(df3))\n",
    "qcg_val_size = len(df3) - qcg_train_size - qcg_test_size\n",
    "\n",
    "qcg_train_data = df3[:qcg_train_size]\n",
    "qcg_test_data = df3[qcg_train_size:qcg_train_size+qcg_test_size]\n",
    "qcg_val_data = df3[qcg_train_size+qcg_test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Hàm Create Dataset\n",
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, X=0,1,2,3-----99   Y=100\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Reshape into X=t,t+1,t+2..t+99 and Y=t+100\n",
    "\n",
    "time_step = 30\n",
    "#Create data X, Y for DXG\n",
    "dxg_X_train, dxg_y_train = create_dataset(dxg_train_data, time_step)\n",
    "dxg_X_val, dxg_yval = create_dataset(dxg_val_data, time_step)\n",
    "dxg_X_test, dxg_ytest = create_dataset(dxg_test_data, time_step)\n",
    "\n",
    "#Create data X, Y for VHM\n",
    "vhm_X_train, vhm_y_train = create_dataset(vhm_train_data, time_step)\n",
    "vhm_X_val, vhm_yval = create_dataset(vhm_val_data, time_step)\n",
    "vhm_X_test, vhm_ytest = create_dataset(vhm_test_data, time_step)\n",
    "\n",
    "#Create data X, Y for DXG\n",
    "qcg_X_train, qcg_y_train = create_dataset(qcg_train_data, time_step)\n",
    "qcg_X_val, qcg_yval = create_dataset(qcg_val_data, time_step)\n",
    "qcg_X_test, qcg_ytest = create_dataset(qcg_test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Reshape input of DXG to be [samples, time steps, features] which is required for TimesNet\n",
    "dxg_X_train =dxg_X_train.reshape(dxg_X_train.shape[0],dxg_X_train.shape[1] , 1)\n",
    "dxg_X_test = dxg_X_test.reshape(dxg_X_test.shape[0],dxg_X_test.shape[1] , 1)\n",
    "dxg_X_val = dxg_X_val.reshape(dxg_X_val.shape[0],dxg_X_val.shape[1] , 1)\n",
    "\n",
    "# 7. Reshape input of VHM to be [samples, time steps, features] which is required for TimesNet\n",
    "vhm_X_train =vhm_X_train.reshape(vhm_X_train.shape[0],vhm_X_train.shape[1] , 1)\n",
    "vhm_X_test = vhm_X_test.reshape(vhm_X_test.shape[0],vhm_X_test.shape[1] , 1)\n",
    "vhm_X_val = vhm_X_val.reshape(vhm_X_val.shape[0],vhm_X_val.shape[1] , 1)\n",
    "\n",
    "# 7. Reshape input of QCG to be [samples, time steps, features] which is required for TimesNet\n",
    "qcg_X_train =qcg_X_train.reshape(qcg_X_train.shape[0],qcg_X_train.shape[1] , 1)\n",
    "qcg_X_test = qcg_X_test.reshape(qcg_X_test.shape[0],qcg_X_test.shape[1] , 1)\n",
    "qcg_X_val = qcg_X_val.reshape(qcg_X_val.shape[0],qcg_X_val.shape[1] , 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the next 30 days\n",
    "def predict_next_days(model, data, n_days, timesteps):\n",
    "    predictions = []\n",
    "    current_seq = data[-timesteps:]\n",
    "    \n",
    "    for _ in range(n_days):\n",
    "        prediction = model.predict(current_seq[np.newaxis, :, :])[0, 0]\n",
    "        predictions.append(prediction)\n",
    "        current_seq = np.append(current_seq[1:], [[prediction]], axis=0)\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Predict the next 30 days\n",
    "last_sequence = prices[-timesteps:]\n",
    "predictions_30_days = predict_next_days(model, last_sequence, 30, timesteps)\n",
    "predictions_30_days = scaler.inverse_transform(predictions_30_days.reshape(-1, 1))\n",
    "\n",
    "# Print the predictions for the next 30 days\n",
    "print(\"Predictions for the next 30 days:\")\n",
    "for i, prediction in enumerate(predictions_30_days):\n",
    "    print(f\"Day {i+1}: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "vhm_train_data_index = pd.RangeIndex(start=0, stop=n_train, step=1)\n",
    "axs[2].plot(scaler.inverse_transform(X_train))\n",
    "vhm_test_data_index = pd.RangeIndex(start=n_train, stop=n_train + n_test, step=1)\n",
    "\n",
    "axs[2].legend(['Train','Test','Predict','Validate','ValidatePred','Predict30days'])\n",
    "\n",
    "\n",
    "axs[2].set_xlabel('VHM',fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
